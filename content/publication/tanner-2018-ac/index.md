---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Generalizability of universal screening measures for behavioral and emotional
  risk
subtitle: ''
summary: ''
authors:
- Nicholas Tanner*
- Katie Eklund
- Stephen P Kilgus
- Austin H Johnson
tags:
- '"article"'
categories: []
date: '2018-01-01'
lastmod: 2020-11-27T11:34:33-08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-11-27T19:34:33.533219Z'
publication_types:
- '2'
abstract: Data derived from universal screening procedures are increasingly utilized
  by schools to identify and provide additional support to students at risk for behavioral
  and emotional concerns. As screening has the potential to be resource intensive,
  effort has been placed on the development of efficient screening procedures, including
  brief behavior rating scales (BBRS). This study utilized classical test theory and
  generalizability theory to examine the extent to which differences among students,
  raters, occasions, and screening measures affect the amount of variance in data
  derived from universal screening procedures. Teacher pairs from three middle school
  classrooms completed two BBRS during fall and spring for each student in their classrooms.
  Correlation coefficients examining interrater reliability, test--retest reliability,
  and convergent validity were generally strong. Generalizability analyses indicated
  that the majority of variance in teacher ratings was attributable to student differences
  across all score comparisons, but differences between teacher ratings for particular
  students accounted for relatively large percentages of error variance among student
  behavior ratings. Although decision studies suggested that increasing the number
  of screening occasions resulted in more generalizable data, they also demonstrated
  that increasing the number of raters not only resulted in more generalizable data
  but also procedures that are more efficient.
publication: '*School Psychology*'
doi: 10.17105/SPR-2017-0044.V47-1
---
