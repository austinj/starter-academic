---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Using consensus building procedures with expert raters to establish comparison
  scores of behavior for Direct Behavior Rating
subtitle: ''
summary: ''
authors:
- Rose Jaffery
- Austin H Johnson
- Mark C Bowler
- T Chris Riley-Tillman
- Sandra M Chafouleas
- Sayward E Harrison
tags:
- '"article"'
categories: []
date: '2015-01-01'
lastmod: 2020-11-27T11:34:35-08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-11-27T19:34:35.082100Z'
publication_types:
- '2'
abstract: To date, rater accuracy when using Direct Behavior Rating (DBR) has been
  evaluated by comparing DBR-derived data to scores yielded through systematic direct
  observation. The purpose of this study was to evaluate an alternative method for
  establishing comparison scores using expert-completed DBR alongside best practices
  in consensus building exercises, to evaluate the accuracy of ratings. Standard procedures
  for obtaining expert data were established and implemented across two sites. Agreement
  indices and comparison scores were derived. Findings indicate that the expert consensus
  building sessions resulted in high agreement between expert raters, lending support
  for this alternative method for identifying comparison scores for behavioral data.
publication: '*Assessment for Effective Intervention*'
doi: 10.1177/1534508415569527
---
